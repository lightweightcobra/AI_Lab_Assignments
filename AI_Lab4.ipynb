{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "def print_state(state):\n",
        "  print('+---+---+---+')\n",
        "  for i in range(3):\n",
        "    for j in range(3):\n",
        "      if state[i][j] == '': print('|   ', end='')\n",
        "      else: print(f'| {state[i][j]} ', end='')\n",
        "    print('|')\n",
        "    print('+---+---+---+')\n",
        "  print('\\n')"
      ],
      "metadata": {
        "id": "PVDp16L6oy05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "  action = None\n",
        "\n",
        "  def __init__(self, state,  parent=None):\n",
        "    self.state = state\n",
        "    self.parent = parent"
      ],
      "metadata": {
        "id": "T98uz6tgt0df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "  def __init__(self):\n",
        "    self.explored_nodes = 0\n",
        "    self.explored_nodes_alpha_beta = 0\n",
        "\n",
        "  def play(self, initial_state, alpha_beta=True):\n",
        "    new_node = Node(initial_state)\n",
        "    if alpha_beta:\n",
        "      return self.MINMAX_alpha_beta(new_node, True, float('-inf'), float('inf'))\n",
        "    else:\n",
        "      return self.MINMAX(new_node, True)\n",
        "\n",
        "\n",
        "  def isGameEnd(self, state):\n",
        "    for i in range(3):\n",
        "      if state[i][0] == state[i][1] == state[i][2] == 'X':\n",
        "          return True\n",
        "      if state[0][i] == state[1][i] == state[2][i] == 'X':\n",
        "          return True\n",
        "      if state[i][0] == state[i][1] == state[i][2] == 'O':\n",
        "          return True\n",
        "      if state[0][i] == state[1][i] == state[2][i] == 'O':\n",
        "          return True\n",
        "    if state[0][0] == state[1][1] == state[2][2] == 'X' or state[0][2] == state[1][1] == state[2][0] == 'X':\n",
        "      return True\n",
        "    if state[0][0] == state[1][1] == state[2][2] == 'O' or state[0][2] == state[1][1] == state[2][0] == 'O':\n",
        "      return True\n",
        "\n",
        "    for i in range(3):\n",
        "      for j in range(3):\n",
        "        if state[i][j] == '': return False\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "  def evaluate(self, state):\n",
        "    for i in range(3):\n",
        "      if state[i][0] == state[i][1] == state[i][2] == 'X':\n",
        "          return 1\n",
        "      elif state[0][i] == state[1][i] == state[2][i] == 'X':\n",
        "          return 1\n",
        "      elif state[i][0] == state[i][1] == state[i][2] == 'O':\n",
        "          return -1\n",
        "      if state[0][i] == state[1][i] == state[2][i] == 'O':\n",
        "          return -1\n",
        "    if state[0][0] == state[1][1] == state[2][2] == 'X' or state[0][2] == state[1][1] == state[2][0] == 'X':\n",
        "      return 1\n",
        "    if state[0][0] == state[1][1] == state[2][2] == 'O' or state[0][2] == state[1][1] == state[2][0] == 'O':\n",
        "      return -1\n",
        "\n",
        "    return 0\n",
        "\n",
        "\n",
        "  def get_next_states(self, state, player1Turn):\n",
        "    next_states = []\n",
        "    for i in range(3):\n",
        "      for j in range(3):\n",
        "        if state[i][j] == 'X' or state[i][j] == 'O': continue\n",
        "        next_state = [row[:] for row in state]\n",
        "        if player1Turn: next_state[i][j] = 'X'\n",
        "        else: next_state[i][j] = 'O'\n",
        "\n",
        "        next_states.append(next_state)\n",
        "    return next_states\n",
        "\n",
        "\n",
        "  def MINMAX(self, curr_node, player1Turn):\n",
        "    self.explored_nodes += 1\n",
        "    if self.isGameEnd(curr_node.state):\n",
        "      return [self.evaluate(curr_node.state), []]\n",
        "\n",
        "    if player1Turn:\n",
        "      maxValue = float('-inf')\n",
        "      action_node_path = []\n",
        "\n",
        "      for next_state in self.get_next_states(curr_node.state, True):\n",
        "        new_node = Node(next_state, curr_node)\n",
        "        eval = self.MINMAX(new_node, False)\n",
        "\n",
        "        if eval[0] > maxValue:\n",
        "          maxValue = eval[0]\n",
        "          action_node_path = [node for node in eval[1]]\n",
        "          action_node_path.append(new_node)\n",
        "\n",
        "      return [maxValue, action_node_path]\n",
        "    else:\n",
        "      minValue = float('inf')\n",
        "      action_node_path = []\n",
        "\n",
        "      for next_state in self.get_next_states(curr_node.state, False):\n",
        "        new_node = Node(next_state, curr_node)\n",
        "        eval = self.MINMAX(new_node, True)\n",
        "\n",
        "        if eval[0] < minValue:\n",
        "          minValue = eval[0]\n",
        "          action_node_path = [node for node in eval[1]]\n",
        "          action_node_path.append(new_node)\n",
        "\n",
        "      return [minValue, action_node_path]\n",
        "\n",
        "\n",
        "  def MINMAX_alpha_beta(self, curr_node, player1Turn, alpha, beta):\n",
        "    self.explored_nodes_alpha_beta += 1\n",
        "    if self.isGameEnd(curr_node.state):\n",
        "      return [self.evaluate(curr_node.state), []]\n",
        "\n",
        "    if player1Turn:\n",
        "      maxValue = float('-inf')\n",
        "      action_node_path = []\n",
        "\n",
        "      for next_state in self.get_next_states(curr_node.state, True):\n",
        "        new_node = Node(next_state, curr_node)\n",
        "        eval = self.MINMAX_alpha_beta(new_node, False, alpha, beta)\n",
        "\n",
        "        if eval[0] > maxValue:\n",
        "          maxValue = eval[0]\n",
        "          action_node_path = [node for node in eval[1]]\n",
        "          action_node_path.append(new_node)\n",
        "\n",
        "        alpha = max(eval[0], alpha)\n",
        "        if beta <= alpha: break\n",
        "\n",
        "      return [maxValue, action_node_path]\n",
        "    else:\n",
        "      minValue = float('inf')\n",
        "      action_node_path = []\n",
        "\n",
        "      for next_state in self.get_next_states(curr_node.state, False):\n",
        "        new_node = Node(next_state, curr_node)\n",
        "        eval = self.MINMAX_alpha_beta(new_node, True, alpha, beta)\n",
        "\n",
        "        if eval[0] < minValue:\n",
        "          minValue = eval[0]\n",
        "          action_node_path = [node for node in eval[1]]\n",
        "          action_node_path.append(new_node)\n",
        "\n",
        "        beta = min(beta, eval[0])\n",
        "        if beta <= alpha: break\n",
        "\n",
        "      return [minValue, action_node_path]"
      ],
      "metadata": {
        "id": "q6tVsrdb-qpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_state = [\n",
        "    ['', '', ''],\n",
        "    ['', '', ''],\n",
        "    ['', '', '']\n",
        "]\n",
        "\n",
        "agent = Agent()\n",
        "\n",
        "best_possible_outcome = agent.play(initial_state, alpha_beta=False)\n",
        "print(f'Best possible outcome {best_possible_outcome[0]}')\n",
        "print(f'Number of nodes explored : {agent.explored_nodes}')\n",
        "\n",
        "best_possible_outcome_alpha_beta = agent.play(initial_state, alpha_beta=True)\n",
        "print(f'Best possible outcome {best_possible_outcome_alpha_beta[0]}')\n",
        "print(f'Number of nodes explored : {agent.explored_nodes_alpha_beta}')\n",
        "\n",
        "best_possible_outcome[1].reverse()"
      ],
      "metadata": {
        "id": "cSKKzD5zNkZ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a34bc0fd-d967-4b5f-e32d-9dd0c4d6ff57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best possible outcome 0\n",
            "Number of nodes explored : 549946\n",
            "Best possible outcome 0\n",
            "Number of nodes explored : 18297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, clear_output\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "class TicTacToeColab:\n",
        "    def __init__(self, state):\n",
        "        self.state = state\n",
        "        self.board_size = 300\n",
        "        self.line_width = 5\n",
        "        self.cell_size = self.board_size // 3\n",
        "        self.images = []\n",
        "\n",
        "    def draw_board(self, title=\"\"):\n",
        "        img = Image.new('RGB', (self.board_size, self.board_size), 'white')\n",
        "        draw = ImageDraw.Draw(img)\n",
        "\n",
        "        font_size = 16\n",
        "        title_font = ImageFont.load_default()\n",
        "        title_position = (self.board_size // 2, 10)\n",
        "        draw.text(title_position, title, fill='black', font=title_font, anchor='mt')\n",
        "\n",
        "        for i in range(1, 3):\n",
        "            x = i * self.cell_size\n",
        "            draw.line([(x, 0), (x, self.board_size)], fill='black', width=self.line_width)\n",
        "            draw.line([(0, x), (self.board_size, x)], fill='black', width=self.line_width)\n",
        "\n",
        "        font_size = 40\n",
        "        font = ImageFont.load_default()\n",
        "\n",
        "        for i in range(3):\n",
        "            for j in range(3):\n",
        "                x, y = j * self.cell_size + self.cell_size // 2, i * self.cell_size + self.cell_size // 2\n",
        "                symbol = self.state[i][j]\n",
        "\n",
        "                if symbol == 'X':\n",
        "                    draw.line([(x - 30, y - 30), (x + 30, y + 30)], fill='black', width=self.line_width)\n",
        "                    draw.line([(x - 30, y + 30), (x + 30, y - 30)], fill='black', width=self.line_width)\n",
        "                elif symbol == 'O':\n",
        "                    draw.ellipse([(x - 30, y - 30), (x + 30, y + 30)], outline='black', width=self.line_width)\n",
        "\n",
        "        self.images.append((img, title))"
      ],
      "metadata": {
        "id": "3yDA_dXyssTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tic_tac_toe = TicTacToeColab(initial_state)\n",
        "\n",
        "for idx, node in enumerate(best_possible_outcome[1]):\n",
        "  tic_tac_toe.state = node.state\n",
        "  title = f\"Move {idx + 1}\"\n",
        "  tic_tac_toe.draw_board(title)\n",
        "\n",
        "\n",
        "print('Best possible Outcome Path : \\n')\n",
        "for img, title in tic_tac_toe.images:\n",
        " print(title)\n",
        " display(img)\n",
        " print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "FXJbzqkCxdVr",
        "outputId": "775f1ef8-e2fc-4e0f-f8bb-65240b983e29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'TicTacToeColab' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-fa8806f907f5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtic_tac_toe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTicTacToeColab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_possible_outcome\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mtic_tac_toe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Move {idx + 1}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'TicTacToeColab' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "class GameState:\n",
        "    def __init__(self, board):\n",
        "        self.board = board\n",
        "\n",
        "    def utility(self):\n",
        "        # Check rows, columns, and diagonals for win/lose/draw\n",
        "        for row in self.board:\n",
        "            if row.count(1) == 3:\n",
        "                return 1\n",
        "            elif row.count(2) == 3:\n",
        "                return -1\n",
        "\n",
        "        for col in range(3):\n",
        "            if self.board[0][col] == self.board[1][col] == self.board[2][col] == 1:\n",
        "                return 1\n",
        "            elif self.board[0][col] == self.board[1][col] == self.board[2][col] == 2:\n",
        "                return -1\n",
        "\n",
        "        if self.board[0][0] == self.board[1][1] == self.board[2][2] == 1:\n",
        "            return 1\n",
        "        elif self.board[0][0] == self.board[1][1] == self.board[2][2] == 2:\n",
        "            return -1\n",
        "\n",
        "        if self.board[0][2] == self.board[1][1] == self.board[2][0] == 1:\n",
        "            return 1\n",
        "        elif self.board[0][2] == self.board[1][1] == self.board[2][0] == 2:\n",
        "            return -1\n",
        "\n",
        "        # Check for draw\n",
        "        if all(cell != 0 for row in self.board for cell in row):\n",
        "            return 0\n",
        "\n",
        "        # Game is ongoing\n",
        "        return None\n",
        "\n",
        "    def actions(self):\n",
        "        possible_actions = []\n",
        "        for i in range(3):\n",
        "            for j in range(3):\n",
        "                if self.board[i][j] == 0:\n",
        "                    possible_actions.append((i, j))\n",
        "        return possible_actions\n",
        "\n",
        "    def result(self, action):\n",
        "        row, col = action\n",
        "        player = 1  # Assuming it's player 1's turn\n",
        "        new_board = [row[:] for row in self.board]\n",
        "        new_board[row][col] = player\n",
        "        return GameState(new_board)\n",
        "\n",
        "# MINIMAX algorithm with alpha-beta pruning\n",
        "def minimax_ab_pruning(state, depth, alpha, beta, maximizing_player):\n",
        "    if depth == 0 or state.utility() is not None:\n",
        "        return state.utility()\n",
        "\n",
        "    if maximizing_player:\n",
        "        max_eval = -math.inf\n",
        "        for action in state.actions():\n",
        "            new_state = state.result(action)\n",
        "            eval = minimax_ab_pruning(new_state, depth - 1, alpha, beta, False)\n",
        "            max_eval = max(max_eval, eval)\n",
        "            alpha = max(alpha, eval)\n",
        "            if beta <= alpha:\n",
        "                break\n",
        "        return max_eval\n",
        "    else:\n",
        "        min_eval = math.inf\n",
        "        for action in state.actions():\n",
        "            new_state = state.result(action)\n",
        "            eval = minimax_ab_pruning(new_state, depth - 1, alpha, beta, True)\n",
        "            min_eval = min(min_eval, eval)\n",
        "            beta = min(beta, eval)\n",
        "            if beta <= alpha:\n",
        "                break\n",
        "        return min_eval\n",
        "\n",
        "# Driver code\n",
        "def main():\n",
        "    initial_state = GameState([[0, 0, 0], [0, 0, 0], [0, 0, 0]])\n",
        "    depth = 9  # Maximum depth for Tic-Tac-Toe is 9\n",
        "    alpha = -math.inf\n",
        "    beta = math.inf\n",
        "    maximizing_player = True\n",
        "    num_evaluated_nodes = minimax_ab_pruning(initial_state, depth, alpha, beta, maximizing_player)\n",
        "    print(\"Number of evaluated nodes:\", num_evaluated_nodes)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "OkN1XlnL-4O-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bffe6fca-2e75-4d6a-dbbb-ac6dd6bcba24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of evaluated nodes: 1\n"
          ]
        }
      ]
    }
  ]
}